{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ERA Framework: Complete Genealogy + Bias Analysis\n",
        "\n",
        "This notebook demonstrates the **complete ERA framework**:\n",
        "\n",
        "1. **Graph-based genealogy tracking** - Map model evolution\n",
        "2. **Three-level bias analysis** - L1/L2/L3 metrics for each model\n",
        "3. **Lineage drift analysis** - How bias propagates through generations\n",
        "\n",
        "## Example Scenario: Legal AI Model Family\n",
        "\n",
        "We'll create a model family:\n",
        "- GPT-3 (foundational)\n",
        "  - ‚Üí GPT-3-Legal (fine-tuned on legal texts)\n",
        "    - ‚Üí GPT-3-Criminal (fine-tuned on criminal law)\n",
        "    - ‚Üí GPT-3-Contract (fine-tuned on contracts)\n",
        "  - ‚á¢ GPT-3-RAG (sibling with retrieval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install ERA framework\n",
        "!pip install -q git+https://github.com/blacklotus1985/ERA-framework.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from era import (\n",
        "    ModelGraph, \n",
        "    ModelNode, \n",
        "    RelationType,\n",
        "    ERAAnalyzer,\n",
        "    HuggingFaceWrapper\n",
        ")\n",
        "from era.graph_viz import visualize_graph, visualize_lineage\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Build Model Genealogy Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create graph\n",
        "graph = ModelGraph()\n",
        "\n",
        "# Add foundational model\n",
        "gpt3 = graph.add_model(\n",
        "    model_id=\"gpt3\",\n",
        "    name=\"GPT-3\",\n",
        "    model_type=\"foundational\",\n",
        "    metadata={\"size\": \"175B\", \"release\": \"2020\"},\n",
        ")\n",
        "\n",
        "# Add fine-tuned models\n",
        "gpt3_legal = graph.add_model(\n",
        "    model_id=\"gpt3-legal\",\n",
        "    name=\"GPT-3 Legal\",\n",
        "    model_type=\"fine_tuned\",\n",
        "    metadata={\"domain\": \"legal documents\", \"examples\": \"50k\"},\n",
        ")\n",
        "\n",
        "gpt3_criminal = graph.add_model(\n",
        "    model_id=\"gpt3-criminal\",\n",
        "    name=\"GPT-3 Criminal Law\",\n",
        "    model_type=\"fine_tuned\",\n",
        "    metadata={\"domain\": \"criminal law\", \"examples\": \"20k\"},\n",
        ")\n",
        "\n",
        "gpt3_contract = graph.add_model(\n",
        "    model_id=\"gpt3-contract\",\n",
        "    name=\"GPT-3 Contracts\",\n",
        "    model_type=\"fine_tuned\",\n",
        "    metadata={\"domain\": \"contract law\", \"examples\": \"30k\"},\n",
        ")\n",
        "\n",
        "# Add architectural variant (sibling)\n",
        "gpt3_rag = graph.add_model(\n",
        "    model_id=\"gpt3-rag\",\n",
        "    name=\"GPT-3 RAG\",\n",
        "    model_type=\"architectural\",\n",
        "    metadata={\"modification\": \"retrieval-augmented\"},\n",
        ")\n",
        "\n",
        "# Add edges (relationships)\n",
        "graph.add_edge(gpt3, gpt3_legal, RelationType.FINE_TUNING)\n",
        "graph.add_edge(gpt3_legal, gpt3_criminal, RelationType.FINE_TUNING)\n",
        "graph.add_edge(gpt3_legal, gpt3_contract, RelationType.FINE_TUNING)\n",
        "graph.add_edge(gpt3, gpt3_rag, RelationType.SIBLING)\n",
        "\n",
        "print(f\"Graph created with {len(graph.nodes)} nodes and {len(graph.edges)} edges\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Run ERA Analysis on Each Model\n",
        "\n",
        "For demonstration, we'll simulate metrics.\n",
        "In production, you'd run actual L1/L2/L3 analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate ERA metrics for each model\n",
        "# In reality, you'd run: analyzer.analyze(test_contexts, target_tokens)\n",
        "\n",
        "metrics_data = {\n",
        "    \"gpt3\": {\n",
        "        \"l1_mean_kl\": 0.0,\n",
        "        \"l2_mean_kl\": 0.0,\n",
        "        \"l3_mean_delta\": 0.0,\n",
        "        \"alignment_score\": 0.0,\n",
        "    },\n",
        "    \"gpt3-legal\": {\n",
        "        \"l1_mean_kl\": 0.25,\n",
        "        \"l2_mean_kl\": 0.89,\n",
        "        \"l3_mean_delta\": 0.00012,\n",
        "        \"alignment_score\": 7417,  # Moderate shallow alignment\n",
        "    },\n",
        "    \"gpt3-criminal\": {\n",
        "        \"l1_mean_kl\": 0.42,\n",
        "        \"l2_mean_kl\": 1.35,\n",
        "        \"l3_mean_delta\": 0.000018,\n",
        "        \"alignment_score\": 75000,  # Very shallow!\n",
        "    },\n",
        "    \"gpt3-contract\": {\n",
        "        \"l1_mean_kl\": 0.31,\n",
        "        \"l2_mean_kl\": 0.95,\n",
        "        \"l3_mean_delta\": 0.00085,\n",
        "        \"alignment_score\": 1118,  # Better depth\n",
        "    },\n",
        "    \"gpt3-rag\": {\n",
        "        \"l1_mean_kl\": 0.18,\n",
        "        \"l2_mean_kl\": 0.52,\n",
        "        \"l3_mean_delta\": 0.00001,  # RAG doesn't change embeddings much\n",
        "        \"alignment_score\": 52000,  # Shallow (architectural, not learning)\n",
        "    },\n",
        "}\n",
        "\n",
        "# Update graph nodes with metrics\n",
        "for model_id, metrics in metrics_data.items():\n",
        "    graph.nodes[model_id].metrics = metrics\n",
        "\n",
        "print(\"ERA metrics added to all models\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Visualize Complete Genealogy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize graph colored by alignment score\n",
        "visualize_graph(\n",
        "    graph,\n",
        "    layout=\"hierarchical\",\n",
        "    highlight_metric=\"alignment_score\",\n",
        "    output_path=\"model_genealogy.png\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Analyze Lineage Drift\n",
        "\n",
        "How does alignment score change from GPT-3 ‚Üí Legal ‚Üí Criminal?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get lineage for criminal law model\n",
        "criminal_lineage = graph.get_lineage(gpt3_criminal)\n",
        "print(f\"Lineage: {' ‚Üí '.join([m.name for m in criminal_lineage])}\")\n",
        "\n",
        "# Analyze alignment score drift\n",
        "drift_analysis = graph.analyze_lineage_drift(gpt3_criminal, \"alignment_score\")\n",
        "\n",
        "print(\"\\nAlignment Score Evolution:\")\n",
        "for model, score in zip(drift_analysis[\"lineage\"], drift_analysis[\"metric_values\"]):\n",
        "    print(f\"  {model}: {score:.0f}\")\n",
        "\n",
        "print(f\"\\nTotal drift: {drift_analysis['total_drift']:.0f}\")\n",
        "print(f\"Verdict: {'SHALLOW ALIGNMENT - DO NOT DEPLOY' if drift_analysis['metric_values'][-1] > 10000 else 'Acceptable depth'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize lineage evolution\n",
        "visualize_lineage(\n",
        "    graph,\n",
        "    gpt3_criminal,\n",
        "    metric=\"alignment_score\",\n",
        "    output_path=\"criminal_lineage.png\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Compare Siblings\n",
        "\n",
        "How does GPT-3 base compare to GPT-3-RAG?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from era.graph_viz import visualize_metric_comparison\n",
        "\n",
        "# Compare all children of GPT-3\n",
        "gpt3_children = graph.get_children(gpt3)\n",
        "print(f\"GPT-3 has {len(gpt3_children)} direct descendants\")\n",
        "\n",
        "visualize_metric_comparison(\n",
        "    graph,\n",
        "    [gpt3] + gpt3_children,\n",
        "    metric=\"alignment_score\",\n",
        "    output_path=\"gpt3_family_comparison.png\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Identify Problematic Models\n",
        "\n",
        "Which models in the family have alignment score > 10,000?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find all models with shallow alignment\n",
        "shallow_threshold = 10000\n",
        "\n",
        "problematic = []\n",
        "for node in graph.nodes.values():\n",
        "    score = node.metrics.get(\"alignment_score\", 0)\n",
        "    if score > shallow_threshold:\n",
        "        problematic.append((node.name, score))\n",
        "\n",
        "print(f\"\\n‚ö†Ô∏è  Models with alignment score > {shallow_threshold}:\")\n",
        "for name, score in sorted(problematic, key=lambda x: x[1], reverse=True):\n",
        "    print(f\"  ‚Ä¢ {name}: {score:.0f} - EXTREMELY SHALLOW\")\n",
        "\n",
        "print(f\"\\n‚ùå {len(problematic)}/{len(graph.nodes)} models are NOT production-ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Save Graph for Later Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save graph to JSON\n",
        "graph.save(\"legal_model_genealogy.json\")\n",
        "\n",
        "# Later, reload:\n",
        "# loaded_graph = ModelGraph.load(\"legal_model_genealogy.json\")\n",
        "\n",
        "print(\"‚úì Graph saved to legal_model_genealogy.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Insights from This Analysis\n",
        "\n",
        "1. **Shallow alignment amplifies with specialization**\n",
        "   - GPT-3 Legal: 7,417 (moderate)\n",
        "   - GPT-3 Criminal: 75,000 (extreme!) \n",
        "   - Verdict: Criminal law model is **parrot**, not genuine learning\n",
        "\n",
        "2. **Architectural modifications don't improve depth**\n",
        "   - GPT-3 RAG: 52,000 (very shallow)\n",
        "   - RAG adds retrieval but doesn't fix shallow embeddings\n",
        "\n",
        "3. **Contract model shows better learning**\n",
        "   - Score: 1,118 (acceptable)\n",
        "   - L3 drift much higher (0.00085 vs 0.000018)\n",
        "   - Actually learned concepts, not just surface patterns\n",
        "\n",
        "## Recommendations\n",
        "\n",
        "- ‚úÖ **Deploy:** GPT-3 Contracts (score < 2,000)\n",
        "- ‚ùå **Do NOT deploy:** GPT-3 Criminal, GPT-3 RAG\n",
        "- üîÑ **Deep retrain:** Criminal law model needs 2-3x more data + longer training\n",
        "\n",
        "---\n",
        "\n",
        "**For more examples:**\n",
        "- Full documentation: https://github.com/blacklotus1985/ERA-framework\n",
        "- Paper (arXiv): [Coming January 2025]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
